import streamlit as st
import pickle
import numpy as np
import os
import torch
import torchvision.transforms as T
from torchvision.models import vit_b_16, ViT_B_16_Weights
from PIL import Image, ImageDraw, ImageFont

# L∆ØU √ù: ƒê·∫£m b·∫£o b·∫°n c√≥ file 'main_script.py' trong c√πng th∆∞ m·ª•c n√†y
# File n√†y ph·∫£i ch·ª©a h√†m 'load_model' m√† 'app (1).py' c·ªßa b·∫°n s·ª≠ d·ª•ng.
try:
    from main_script import load_model
except ImportError:
    st.error("L·ªñI CRITICAL: Kh√¥ng t√¨m th·∫•y file 'main_script.py'.")
    st.error("Vui l√≤ng t·∫°o file 'main_script.py' ch·ª©a h√†m 'load_model' ƒë·ªÉ t·∫£i m√¥ h√¨nh Faster R-CNN.")
    st.stop()


# =======================
# 1. C·∫•u h√¨nh chung
# =======================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))


# ============================================
# 2. M√¥ h√¨nh 1: PH√ÇN LO·∫†I (ViT + Softmax)
# ============================================

@st.cache_resource
def load_classification_models():
    """T·∫£i m√¥ h√¨nh ViT v√† m√¥ h√¨nh Softmax ƒë√£ hu·∫•n luy·ªán."""
    st.info("ƒêang t·∫£i m√¥ h√¨nh Ph√¢n lo·∫°i (ViT + Softmax)...")
    
    # 1. T·∫£i m√¥ h√¨nh ViT
    try:
        weights = ViT_B_16_Weights.IMAGENET1K_V1
        transform_for_vit = weights.transforms()
        vit_model = vit_b_16(weights=weights).to(DEVICE)
    except Exception:
        st.warning("Kh√¥ng th·ªÉ t·∫£i weights m·ªõi c·ªßa ViT, th·ª≠ ph∆∞∆°ng ph√°p c≈©.")
        vit_model = vit_b_16(pretrained=True).to(DEVICE)
        transform_for_vit = T.Compose([
            T.Resize(256), T.CenterCrop(224), T.ToTensor(),
            T.Normalize(mean=[0.456, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    if hasattr(vit_model, "heads"):
        vit_model.heads.head = torch.nn.Identity()
    else:
        vit_model.head = torch.nn.Identity()
    vit_model.eval()

    # 2. T·∫£i m√¥ h√¨nh Softmax
    MODEL_PATH = os.path.join(SCRIPT_DIR, "softmax_model.pkl")
    
    if not os.path.exists(MODEL_PATH):
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y 'softmax_model.pkl'.")
        return None, None, None, None, None, None, None

    # T·∫£i file .pkl (ch·ªâ ch·ª©a W, b, label_map)
    with open(MODEL_PATH, "rb") as f:
        softmax_model = pickle.load(f)

    # --- S·ª¨A L·ªñI KEYERROR B·∫∞NG C√ÅCH G√ÅN GI√Å TR·ªä GI·∫¢ ---
    # Ch√∫ng ta b·ªè qua b∆∞·ªõc chu·∫©n h√≥a v√¨ file .pkl kh√¥ng c√≥ 'mean' v√† 'std'
    # C·∫¢NH B√ÅO: ƒêi·ªÅu n√†y s·∫Ω l√†m cho d·ª± ƒëo√°n B·ªä SAI
    st.warning("C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y 'mean' v√† 'std' trong file model. B·ªè qua b∆∞·ªõc chu·∫©n h√≥a. K·∫øt qu·∫£ ph√¢n lo·∫°i (M√¥ h√¨nh 1) s·∫Ω KH√îNG ch√≠nh x√°c.")
    feature_mean = 0.0  # G√°n gi√° tr·ªã gi·∫£
    feature_std = 1.0   # G√°n gi√° tr·ªã gi·∫£ (ƒë·ªÉ ph√©p chia kh√¥ng b·ªã l·ªói)
    # --- K·∫æT TH√öC S·ª¨A L·ªñI ---

    W, b = softmax_model["W"], softmax_model["b"]
    original_label_map = softmax_model["label_map"]
    label_map = {v: k for k, v in original_label_map.items()}
    
    st.success("T·∫£i xong m√¥ h√¨nh Ph√¢n lo·∫°i.")
    return vit_model, transform_for_vit, W, b, feature_mean, feature_std, label_map
# --- K·∫æT TH√öC H√ÄM ---


def extract_vit_features(pil_image, vit, transform, device):
    if pil_image.mode != "RGB":
        pil_image = pil_image.convert("RGB")
    img_t = transform(pil_image)
    batch_t = torch.unsqueeze(img_t, 0).to(device)
    with torch.no_grad():
        features = vit(batch_t)
    return features.cpu().numpy()

def softmax(z):
    if z.ndim == 1: z = z.reshape(1, -1)
    z = z - np.max(z, axis=1, keepdims=True)
    exp_z = np.exp(z)
    return exp_z / np.sum(exp_z, axis=1, keepdims=True)

def predict_classification(X_feature, W, b):
    scores = X_feature @ W + b
    probs = softmax(scores)
    preds = np.argmax(probs, axis=1)
    return preds, probs


# ================================================
# 3. M√¥ h√¨nh 2: PH√ÅT HI·ªÜN L·ªñI (Faster R-CNN)
# ================================================

@st.cache_resource
def load_detection_model():
    """T·∫£i m√¥ h√¨nh Faster R-CNN."""
    st.info("ƒêang t·∫£i m√¥ h√¨nh Ph√°t hi·ªán l·ªói (Faster R-CNN)...")
    model_path = os.path.join(SCRIPT_DIR, 'fasterrcnn_phone_defect.pth')
    if not os.path.exists(model_path):
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y 'fasterrcnn_phone_defect.pth' t·∫°i '{model_path}'.")
        return None, None
        
    model = load_model(model_path) # <-- S·ª≠ d·ª•ng h√†m t·ª´ 'main_script.py'
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    st.success("T·∫£i xong m√¥ h√¨nh Ph√°t hi·ªán l·ªói.")
    return model, device

def predict_for_webapp(model, device, image_pil, score_thresh=0.6):
    """D·ª± ƒëo√°n v√† tr·∫£ v·ªÅ tr·∫°ng th√°i + ·∫£nh ƒë√£ v·∫Ω."""
    transform = T.ToTensor()
    img_tensor = transform(image_pil).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)[0]
    
    image_with_boxes = image_pil.copy() 
    draw = ImageDraw.Draw(image_with_boxes)
    label_map = {1: "KH√îNG V·ª†", 2: "V·ª†"}
    
    is_defective = False
    detected_object = False 

    for box, score, label in zip(outputs["boxes"], outputs["scores"], outputs["labels"]):
        if score > score_thresh:
            detected_object = True 
            box = box.cpu().numpy()
            label_id = label.cpu().numpy().item()
            
            if label_id == 2: 
                is_defective = True
            
            color = "lime" if label_id == 1 else "red"
            draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=color, width=3)
            
            text = f"{label_map.get(label_id, 'N/A')}: {score:.2f}"
            text_x, text_y = box[0], max(0, box[1] - 20)
            bbox = draw.textbbox((text_x, text_y), text)
            draw.rectangle(bbox, fill="black")
            draw.text((text_x, text_y), text, fill="yellow")

    if not detected_object:
        return "KH√îNG T√åM TH·∫§Y", image_pil
    elif is_defective:
        return "V·ª†", image_with_boxes
    else:
        return "KH√îNG V·ª†", image_with_boxes


# ===================================
# 4. GIAO DI·ªÜN STREAMLIT G·ªòP
# ===================================
st.set_page_config(layout="wide", page_title="Ph√¢n t√≠ch ƒêi·ªán tho·∫°i")
st.title("·ª®ng d·ª•ng Ph√¢n t√≠ch L·ªói M√†n h√¨nh ƒêi·ªán tho·∫°i (G·ªôp 2 M√¥ h√¨nh)")
st.write("T·∫£i l√™n m·ªôt ·∫£nh ƒë·ªÉ ch·∫°y ƒë·ªìng th·ªùi m√¥ h√¨nh Ph√¢n lo·∫°i (ViT) v√† Ph√°t hi·ªán l·ªói (Faster R-CNN).")
st.divider()

# --- T·∫£i t·∫•t c·∫£ m√¥ h√¨nh ---
class_models = load_classification_models()
vit_model, transform_for_vit, W, b, feature_mean, feature_std, label_map = class_models
detect_model, detect_device = load_detection_model()

# --- Ki·ªÉm tra n·∫øu t·∫£i m√¥ h√¨nh th·∫•t b·∫°i ---
if any(m is None for m in class_models) or detect_model is None:
    st.error("M·ªôt ho·∫∑c c·∫£ hai m√¥ h√¨nh ƒë√£ kh√¥ng th·ªÉ t·∫£i. Vui l√≤ng ki·ªÉm tra l·∫°i file v√† ƒë∆∞·ªùng d·∫´n.")
    st.stop()

# --- Giao di·ªán t·∫£i file ---
uploaded_file = st.file_uploader("Ch·ªçn m·ªôt ·∫£nh", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # ƒê·ªçc ·∫£nh 1 l·∫ßn duy nh·∫•t
    image_pil = Image.open(uploaded_file).convert("RGB")
    
    # Hi·ªÉn th·ªã ·∫£nh g·ªëc
    st.image(image_pil, caption="·∫¢nh b·∫°n ƒë√£ t·∫£i l√™n", use_column_width=False, width=400)
    st.divider()

    # T·∫°o 2 c·ªôt cho 2 k·∫øt qu·∫£
    col1, col2 = st.columns(2)

    # --- C·ªòT 1: K·∫æT QU·∫¢ PH√ÇN LO·∫†I (ViT) ---
    with col1:
        st.header("1. K·∫øt qu·∫£ Ph√¢n lo·∫°i (T·ªïng th·ªÉ)")
        with st.spinner('ƒêang ph√¢n lo·∫°i...'):
            # 1. Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ViT
            vit_features = extract_vit_features(image_pil, vit_model, transform_for_vit, DEVICE)
            
            # 2. Chu·∫©n h√≥a (B∆Ø·ªöC N√ÄY S·∫º B·ªä B·ªé QUA V√å MEAN=0, STD=1)
            standardized_features = (vit_features - feature_mean) / feature_std
            
            # 3. D·ª± ƒëo√°n (S·∫º B·ªä SAI)
            pred_class, probs = predict_classification(standardized_features, W, b)
            
            predicted_label_index = int(pred_class[0])
            predicted_label_name = label_map[predicted_label_index]

            if predicted_label_name == "defective":
                st.error(f"üëâ D·ª± ƒëo√°n: {predicted_label_name.upper()} (L·ªói)")
            elif predicted_label_name == "non-defective":
                st.success(f"üëâ D·ª± ƒëo√°n: {predicted_label_name.upper()} (Kh√¥ng l·ªói)")
            else:
                st.warning(f"üëâ D·ª± ƒëo√°n: {predicted_label_name.upper()}")

            st.subheader("üìä X√°c su·∫•t (ViT):")
            for i, p in enumerate(probs[0]):
                class_name = label_map[i]
                st.write(f"- **{class_name}**: `{p:.4f}`")

    # --- C·ªòT 2: K·∫æT QU·∫¢ PH√ÅT HI·ªÜN L·ªñI (FASTER R-CNN) ---
    with col2:
        st.header("2. K·∫øt qu·∫£ Ph√°t hi·ªán (Chi ti·∫øt)")
        with st.spinner('ƒêang ph√°t hi·ªán l·ªói...'):
            # Ch·∫°y d·ª± ƒëo√°n v√† nh·∫≠n tr·∫°ng th√°i
            # Chuy·ªÉn .copy() ƒë·ªÉ m√¥ h√¨nh n√†y v·∫Ω l√™n ·∫£nh
            detection_status, result_image = predict_for_webapp(
                detect_model, 
                detect_device, 
                image_pil.copy(), 
                score_thresh=0.5
            )
            
            if detection_status == "V·ª†":
                st.error("‚ùå **K·∫æT QU·∫¢:\nPh√°t hi·ªán V·ª†**")
            elif detection_status == "KH√îNG V·ª†":
                st.success("‚úÖ **K·∫æT QU·∫¢:\nKh√¥ng ph√°t hi·ªán v·ª°**")
            else: # "KH√îNG T√åM TH·∫§Y"
                st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y ƒëi·ªán tho·∫°i trong ·∫£nh.**")
            
            st.image(result_image, caption="·∫¢nh ƒë√£ v·∫Ω khung", use_column_width=True)

else:
    st.info("H√£y t·∫£i m·ªôt ·∫£nh l√™n ƒë·ªÉ xem k·∫øt qu·∫£ t·ª´ c·∫£ hai m√¥ h√¨nh.")
